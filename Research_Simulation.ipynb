{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPfdMjvOEeNSkE7GrI4ojB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirhoseinaghaei/Research_Simulation/blob/main/Research_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment"
      ],
      "metadata": {
        "id": "XhG3KYLzzBDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AoI Scheduler"
      ],
      "metadata": {
        "id": "uU5KmVY7zhNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from Rudder import LessonBuffer\n",
        "from Environment import Environment\n",
        "from Rudder import RRLSTM as LSTM\n",
        "import torch\n",
        "import time as Time\n",
        "import random\n",
        "\n",
        "lb_size = 2048\n",
        "n_lstm = 16\n",
        "max_time = 50\n",
        "policy_lr = 0.1\n",
        "lstm_lr = 1e-2\n",
        "l2_regularization = 1e-6\n",
        "avg_window = 750\n",
        "\n",
        "Lesson_buffer = LessonBuffer(1000, 25, 5)\n",
        "episode = 0\n",
        "rudder_lstm = LSTM(state_input_size=5, n_actions= 2, buffer=Lesson_buffer, n_units=n_lstm,\n",
        "                        lstm_lr=lstm_lr, l2_regularization=l2_regularization, return_scaling=10,\n",
        "                        lstm_batch_size=8, continuous_pred_factor=0.5)\n",
        "\n",
        "# rudder_lstm.load_state_dict(torch.load('rudder_lstm.pt'))\n",
        "environment = Environment(100,25)\n",
        "environment.CreateStates()\n",
        "episode = 0\n",
        "for i in range(200000):\n",
        "    episode += 1\n",
        "    environment.reset_paramter()\n",
        "    state = environment.reset_state()\n",
        "    rewards = []\n",
        "    states = [state]\n",
        "    actions = []\n",
        "    done = False\n",
        "    while not done:\n",
        "        if environment.state.Ra == 0 and environment.state.U == 0:\n",
        "            action = 0\n",
        "        elif environment.state.Ra == 1 and environment.state.U == 0:\n",
        "            action = 1 if  random.uniform(0, 1) < 0 else 0\n",
        "        elif environment.state.Ra == 0 and environment.state.U == 24:\n",
        "            action = 1\n",
        "        elif environment.state.U > 0:\n",
        "            action = 0\n",
        "        state, reward, done = environment.step(action)\n",
        "        actions.append(action)\n",
        "        states.append(state)\n",
        "        rewards.append(reward) \n",
        "        if done: \n",
        "            # for i in states:\n",
        "            #     print(i)\n",
        "            for i in states: \n",
        "                if i[1] == \"Ch1\":\n",
        "                    i[1] = 1\n",
        "                else:\n",
        "                    i[1] = 0\n",
        "            # print(states)\n",
        "            # Time.sleep(5)\n",
        "            states = np.stack(states)\n",
        "            states = states.astype(int)\n",
        "            rewards = np.array(rewards, dtype = np.float32)\n",
        "            actions = np.array(actions)\n",
        "            Lesson_buffer.add(states = states, actions = actions, rewards = rewards)\n",
        "            # print(\"++++++++++++++++++++++++++\")    \n",
        "            # and Lesson_buffer.different_returns_encountered()    \n",
        "            if  Lesson_buffer.full_enough() :\n",
        "                    # print(\"different_returns_encountered\")        \n",
        "                    # If RUDDER is run, the LSTM is trained after each episode until its loss is below a threshold.\n",
        "                    # Samples will be drawn from the lessons buffer.\n",
        "                    if episode % 25 == 0:\n",
        "\n",
        "                        print(\"Truee\")\n",
        "                        print(episode)\n",
        "                        rudder_lstm.train(episode=episode)\n",
        "                    if episode >= 1600: \n",
        "                        torch.save(rudder_lstm.state_dict(), 'rudder_lstm.pt')\n",
        "                    # Then the LSTM is used to redistribute the reward.\n",
        "            # print(rewards)\n",
        "            # print(states)\n",
        "            # print(actions)\n",
        "            rewards = rudder_lstm.redistribute_reward(states=np.expand_dims(states, 0),\n",
        "                                                    actions=np.expand_dims(actions, 0))[0, :]\n",
        "            # print(rewards)\n",
        "            # Time.sleep(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "56Ai2oGRzgyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s0JFPGVbznBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}