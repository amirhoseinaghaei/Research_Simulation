{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW76zOrsHP8dl6Z72G5ypY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirhoseinaghaei/Research_Simulation/blob/main/Simulation_With_Quantum_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0RZzWZ8lTwM",
        "outputId": "1b65b9af-0578-4d27-a495-a829489e2267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: No such file or directory\n",
            "/bin/bash: google-drive-ocamlfuse: command not found\n",
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive/Research_Simmulation\n"
          ]
        }
      ],
      "source": [
        "!fusermount -u drive\n",
        "!google-drive-ocamlfuse drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')\n",
        "%cd gdrive/MyDrive/Research_Simmulation/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.7.0\n",
        "!pip install tensorflow-quantum==0.7.2\n",
        "!pip install gym==0.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AsUgE0w8JuUz",
        "outputId": "7639d444-4812-40e2-d3da-0ff40305817c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.22.4)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (4.5.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.51.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (2.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (2.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (15.0.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.16.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (63.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, flatbuffers, keras-preprocessing, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed flatbuffers-2.0.7 keras-2.7.0 keras-preprocessing-1.1.2 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-quantum==0.7.2\n",
            "  Downloading tensorflow_quantum-0.7.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googleapis-common-protos==1.52.0\n",
            "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.17.3\n",
            "  Downloading protobuf-3.17.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core==1.21.0\n",
            "  Downloading google_api_core-1.21.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cirq-google>=0.13.1\n",
            "  Downloading cirq_google-1.1.0-py3-none-any.whl (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 KB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.8\n",
            "  Downloading sympy-1.8-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cirq-core==0.13.1\n",
            "  Downloading cirq_core-0.13.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth==1.18.0\n",
            "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.65.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.10.1)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.22.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.7.1)\n",
            "Collecting duet~=0.2.0\n",
            "  Downloading duet-0.2.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.5.0)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.9/dist-packages (from cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.4.0)\n",
            "Collecting networkx~=2.4\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2022.7.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2.27.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (63.4.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth==1.18.0->tensorflow-quantum==0.7.2) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth==1.18.0->tensorflow-quantum==0.7.2) (0.2.8)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy==1.8->tensorflow-quantum==0.7.2) (1.3.0)\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from cirq-google>=0.13.1->tensorflow-quantum==0.7.2) (1.22.2)\n",
            "Collecting cirq-google>=0.13.1\n",
            "  Downloading cirq_google-1.0.0-py3-none-any.whl (576 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m576.5/576.5 KB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading cirq_google-0.15.0-py3-none-any.whl (641 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m641.8/641.8 KB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading cirq_google-0.14.1-py3-none-any.whl (541 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 KB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading cirq_google-0.14.0-py3-none-any.whl (541 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 KB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading cirq_google-0.13.1-py3-none-any.whl (437 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.1/437.1 KB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading google_api_core-1.33.2-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.33.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.33.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.6-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.5-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.4-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.29.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.28.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.27.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.26.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.26.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.26.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.25.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.25.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.24.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.22.4-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.22.3-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.22.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_api_core-1.22.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core==1.21.0->tensorflow-quantum==0.7.2) (1.51.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (7.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (4.39.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (23.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tensorflow-quantum==0.7.2) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum==0.7.2) (2.0.12)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum==0.7.2) (3.15.0)\n",
            "Installing collected packages: sympy, protobuf, networkx, duet, cachetools, googleapis-common-protos, google-auth, google-api-core, cirq-core, cirq-google, tensorflow-quantum\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.11.1\n",
            "    Uninstalling sympy-1.11.1:\n",
            "      Successfully uninstalled sympy-1.11.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.58.0\n",
            "    Uninstalling googleapis-common-protos-1.58.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.58.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.16.2\n",
            "    Uninstalling google-auth-2.16.2:\n",
            "      Successfully uninstalled google-auth-2.16.2\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.0\n",
            "    Uninstalling google-api-core-2.11.0:\n",
            "      Successfully uninstalled google-api-core-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-hub 0.13.0 requires protobuf>=3.19.6, but you have protobuf 3.17.3 which is incompatible.\n",
            "pydata-google-auth 1.7.0 requires google-auth<3.0dev,>=1.25.0; python_version >= \"3.6\", but you have google-auth 1.18.0 which is incompatible.\n",
            "proto-plus 1.22.2 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.17.3 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires google-auth>=1.25.0, but you have google-auth 1.18.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-cloud-storage 2.7.0 requires google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-storage 2.7.0 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.18.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-cloud-core 2.3.2 requires google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.6, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-core 2.3.2 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.18.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.17.3 which is incompatible.\n",
            "google-api-python-client 2.70.0 requires google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\n",
            "google-api-python-client 2.70.0 requires google-auth<3.0.0dev,>=1.19.0, but you have google-auth 1.18.0 which is incompatible.\n",
            "firebase-admin 5.3.0 requires google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\", but you have google-api-core 1.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-4.2.4 cirq-core-0.13.1 cirq-google-0.13.1 duet-0.2.7 google-api-core-1.21.0 google-auth-1.18.0 googleapis-common-protos-1.52.0 networkx-2.8.8 protobuf-3.17.3 sympy-1.8 tensorflow-quantum-0.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym==0.18.0 in /usr/local/lib/python3.9/dist-packages (0.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from gym==0.18.0) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.9/dist-packages (from gym==0.18.0) (1.22.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.18.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow<=7.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.18.0) (7.2.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.18.0) (1.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.18.0) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import gym, cirq, sympy\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from collections import deque, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "n1lKvQjaI-46",
        "outputId": "c60b7bc4-f6b3-4c1c-aaaa-212d4f35d56c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/load_module.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_to_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0mRaises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/_tfq_simulate_ops.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e012d57d9fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_resources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_quantum\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcirq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Import basic ops and op getters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from tensorflow_quantum.core import (append_circuit, get_expectation_op,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                      \u001b[0mget_sampled_expectation_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                      \u001b[0mget_sampling_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Imports to tensorflow_quantum.core.* level.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Import getters for constructing ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from tensorflow_quantum.core.ops import (get_expectation_op,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                          \u001b[0mget_sampled_expectation_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                          \u001b[0mget_sampling_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Import getters for constructing ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from tensorflow_quantum.core.ops.circuit_execution_ops import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mget_expectation_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sampled_expectation_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_sampling_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     get_state_op)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/circuit_execution_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcirq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m from tensorflow_quantum.core.ops import (cirq_ops, tfq_simulate_ops,\n\u001b[0m\u001b[1;32m     21\u001b[0m                                          tfq_utility_ops)\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_quantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantum_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/tfq_simulate_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_quantum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mSIM_OP_MODULE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_tfq_simulate_ops.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow_quantum/core/ops/load_module.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     44\u001b[0m         path = os.path.join(get_python_lib(), \"tensorflow_quantum/core/ops\",\n\u001b[1;32m     45\u001b[0m                             name)\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mwrappers\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mOps\u001b[0m \u001b[0mdefined\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0mRaises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0munable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /usr/lib/python3/dist-packages/tensorflow_quantum/core/ops/_tfq_simulate_ops.so: cannot open shared object file: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "# from Environment import Actor\n",
        "from Rudder import LessonBuffer\n",
        "from Environment import Environment\n",
        "from Rudder import RRLSTM as LSTM\n",
        "import torch\n",
        "import time as Time\n",
        "import random\n",
        "from PolicyUpdater import PolicyUpdater\n",
        "from tqdm import tqdm\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def gather_episodes(num_of_episodes , model):\n",
        "  time1 = datetime.now()\n",
        "  trajectories = [defaultdict(list) for _ in range(num_of_episodes)]\n",
        "  environment = Environment(1000,100)\n",
        "  environment.CreateStates()\n",
        "  episode = 0\n",
        "  for i in tqdm(range(num_of_episodes)):\n",
        "      episode += 1\n",
        "      environment.reset_paramter()\n",
        "      state, _ = environment.reset_state()\n",
        "      if state[1] == \"Ch1\":\n",
        "          state[1] = 1\n",
        "      else:\n",
        "          state[1] = 0\n",
        "      environment.generate_channel_state_list_for_whole_sequence(state[1])\n",
        "      rewards = []\n",
        "      states = [state]\n",
        "      actions = []\n",
        "      done = False\n",
        "      name = f'({state[0]}, {state[1]}, {state[2]}, {state[3]}, {state[4]})'\n",
        "      policy = (model([tf.convert_to_tensor([state.astype(float)])])).numpy()\n",
        "      while not done:\n",
        " \n",
        "          action = np.random.choice(n_actions, p=policy[0])\n",
        "          if environment.state.Ra == 0 and environment.state.U == 0:\n",
        "              action = 0\n",
        "          if environment.state.U > 0:\n",
        "              action = 0\n",
        "          if environment.sendbackaction == True:\n",
        "              action = 1\n",
        "\n",
        "          state, reward, done = environment.step(action)\n",
        "          if state[1] == \"Ch1\":\n",
        "              state[1] = 1\n",
        "          else:\n",
        "              state[1] = 0\n",
        "          state = np.stack(state)\n",
        "          state = state.astype(int)\n",
        "          reward = np.array(reward, dtype = np.float32)\n",
        "          action = np.array(action)\n",
        "          # actions.append(action)\n",
        "          # states.append(state)\n",
        "          # rewards.append(reward) \n",
        "          trajectories[episode-1][\"states\"].append(state)\n",
        "          trajectories[episode-1][\"actions\"].append(action)\n",
        "          trajectories[episode-1][\"rewards\"].append(reward)\n",
        "          # if done: \n",
        "\n",
        "          #     res = np.nonzero(rewards)[0]\n",
        "          #     if rewards[-1] == 0 and len(res) > 0 :\n",
        "          #       rewards[-1] = sum(rewards)\n",
        "          #       rewards[-1] = rewards[-1]\n",
        "          #       rewards[res[0]] = 0\n",
        "          #     else:\n",
        "          #       rewards[-1] = rewards[-1]\n",
        "                \n",
        "              # for i in states: \n",
        "              #     if i[1] == \"Ch1\":\n",
        "              #         i[1] = 1\n",
        "              #     else:\n",
        "              #         i[1] = 0\n",
        "\n",
        "         \n",
        "  return trajectories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5S1HqcXlibB",
        "outputId": "9f545d2d-c920-4cd9-a4e7-ef83b58cd519"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trajectories = gather_episodes(1, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cBT2GsJcpbp5",
        "outputId": "704ca50d-f071-4e64-91f9-3991d5cbdd10"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-95f893f6c17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = ((trajectories[0][\"actions\"]))\n"
      ],
      "metadata": {
        "id": "qX63yE3vpsyI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_qubit_rotation(qubit, symbols):\n",
        "    \"\"\"\n",
        "    Returns Cirq gates that apply a rotation of the bloch sphere about the X,\n",
        "    Y and Z axis, specified by the values in `symbols`.\n",
        "    \"\"\"\n",
        "    return [cirq.rx(symbols[0])(qubit),\n",
        "            cirq.ry(symbols[1])(qubit),\n",
        "            cirq.rz(symbols[2])(qubit)]\n",
        "\n",
        "def entangling_layer(qubits):\n",
        "    \"\"\"\n",
        "    Returns a layer of CZ entangling gates on `qubits` (arranged in a circular topology).\n",
        "    \"\"\"\n",
        "    cz_ops = [cirq.CZ(q0, q1) for q0, q1 in zip(qubits, qubits[1:])]\n",
        "    cz_ops += ([cirq.CZ(qubits[0], qubits[-1])] if len(qubits) != 2 else [])\n",
        "    return cz_ops\n",
        "def generate_circuit(qubits, n_layers):\n",
        "    \"\"\"Prepares a data re-uploading circuit on `qubits` with `n_layers` layers.\"\"\"\n",
        "    # Number of qubits\n",
        "    n_qubits = len(qubits)\n",
        "    \n",
        "    # Sympy symbols for variational angles\n",
        "    params = sympy.symbols(f'theta(0:{3*(n_layers+1)*n_qubits})')\n",
        "    params = np.asarray(params).reshape((n_layers + 1, n_qubits, 3))\n",
        "    \n",
        "    # Sympy symbols for encoding angles\n",
        "    inputs = sympy.symbols(f'x(0:{n_layers})'+f'_(0:{n_qubits})')\n",
        "    inputs = np.asarray(inputs).reshape((n_layers, n_qubits))\n",
        "    \n",
        "    # Define circuit\n",
        "    circuit = cirq.Circuit()\n",
        "    for l in range(n_layers):\n",
        "        # Variational layer\n",
        "        circuit += cirq.Circuit(one_qubit_rotation(q, params[l, i]) for i, q in enumerate(qubits))\n",
        "        circuit += entangling_layer(qubits)\n",
        "        # Encoding layer\n",
        "        circuit += cirq.Circuit(cirq.rx(inputs[l, i])(q) for i, q in enumerate(qubits))\n",
        "\n",
        "    # Last varitional layer\n",
        "    circuit += cirq.Circuit(one_qubit_rotation(q, params[n_layers, i]) for i,q in enumerate(qubits))\n",
        "    \n",
        "    return circuit, list(params.flat), list(inputs.flat)"
      ],
      "metadata": {
        "id": "6hLiNkNmpey_"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits, n_layers = 3, 1\n",
        "qubits = cirq.GridQubit.rect(1, n_qubits)\n",
        "circuit, _, _ = generate_circuit(qubits, n_layers)\n",
        "SVGCircuit(circuit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "rYuD_UcbJPQB",
        "outputId": "80e77176-0951-4cbe-ecc5-f53012d30655"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Arial' not found.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7fa1d2c9ef40>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1016.1524609375002\" height=\"150.0\"><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"986.1524609375002\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"404.74449218750004\" x2=\"404.74449218750004\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"464.74449218750004\" x2=\"464.74449218750004\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"524.7444921875001\" x2=\"524.7444921875001\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta0)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta3)</text><rect x=\"79.517734375\" y=\"105.0\" width=\"82.31109375000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.67328125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta6)</text><rect x=\"181.82882812500003\" y=\"5.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta1)</text><rect x=\"181.82882812500003\" y=\"55.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta4)</text><rect x=\"181.82882812500003\" y=\"105.0\" width=\"81.54109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"222.59937500000004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta7)</text><rect x=\"283.36992187500005\" y=\"5.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta2)</text><rect x=\"283.36992187500005\" y=\"55.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta5)</text><rect x=\"283.36992187500005\" y=\"105.0\" width=\"81.37457031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"324.0572070312501\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta8)</text><circle cx=\"404.74449218750004\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"404.74449218750004\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"464.74449218750004\" cy=\"75.0\" r=\"10.0\" /><circle cx=\"464.74449218750004\" cy=\"125.0\" r=\"10.0\" /><circle cx=\"524.7444921875001\" cy=\"25.0\" r=\"10.0\" /><circle cx=\"524.7444921875001\" cy=\"125.0\" r=\"10.0\" /><rect x=\"564.7444921875001\" y=\"5.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_0)</text><rect x=\"564.7444921875001\" y=\"55.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_1)</text><rect x=\"564.7444921875001\" y=\"105.0\" width=\"69.45953125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.4742578125001\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(x0_2)</text><rect x=\"654.2040234375002\" y=\"5.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta9)</text><rect x=\"654.2040234375002\" y=\"55.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta12)</text><rect x=\"654.2040234375002\" y=\"105.0\" width=\"91.21832031250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"699.8131835937502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(theta15)</text><rect x=\"765.4223437500002\" y=\"5.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta10)</text><rect x=\"765.4223437500002\" y=\"55.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta13)</text><rect x=\"765.4223437500002\" y=\"105.0\" width=\"90.4483203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"810.6465039062502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(theta16)</text><rect x=\"875.8706640625002\" y=\"5.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta11)</text><rect x=\"875.8706640625002\" y=\"55.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta14)</text><rect x=\"875.8706640625002\" y=\"105.0\" width=\"90.28179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"921.0115625000002\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(theta17)</text></svg>"
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReUploadingPQC(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Performs the transformation (s_1, ..., s_d) -> (theta_1, ..., theta_N, lmbd[1][1]s_1, ..., lmbd[1][M]s_1,\n",
        "        ......., lmbd[d][1]s_d, ..., lmbd[d][M]s_d) for d=input_dim, N=theta_dim and M=n_layers.\n",
        "    An activation function from tf.keras.activations, specified by `activation` ('linear' by default) is\n",
        "        then applied to all lmbd[i][j]s_i.\n",
        "    All angles are finally permuted to follow the alphabetical order of their symbol names, as processed\n",
        "        by the ControlledPQC.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, qubits, n_layers, observables, activation=\"linear\", name=\"re-uploading_PQC\"):\n",
        "        super(ReUploadingPQC, self).__init__(name=name)\n",
        "        self.n_layers = n_layers\n",
        "        self.n_qubits = len(qubits)\n",
        "\n",
        "        circuit, theta_symbols, input_symbols = generate_circuit(qubits, n_layers)\n",
        "\n",
        "        theta_init = tf.random_uniform_initializer(minval=0.0, maxval=np.pi)\n",
        "        self.theta = tf.Variable(\n",
        "            initial_value=theta_init(shape=(1, len(theta_symbols)), dtype=\"float32\"),\n",
        "            trainable=True, name=\"thetas\"\n",
        "        )\n",
        "        \n",
        "        lmbd_init = tf.ones(shape=(self.n_qubits * self.n_layers,))\n",
        "        self.lmbd = tf.Variable(\n",
        "            initial_value=lmbd_init, dtype=\"float32\", trainable=True, name=\"lambdas\"\n",
        "        )\n",
        "        \n",
        "        # Define explicit symbol order.\n",
        "        symbols = [str(symb) for symb in theta_symbols + input_symbols]\n",
        "        self.indices = tf.constant([symbols.index(a) for a in sorted(symbols)])\n",
        "        \n",
        "        self.activation = activation\n",
        "        self.empty_circuit = tfq.convert_to_tensor([cirq.Circuit()])\n",
        "        self.computation_layer = tfq.layers.ControlledPQC(circuit, observables)        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs[0] = encoding data for the state.\n",
        "        batch_dim = tf.gather(tf.shape(inputs[0]), 0)\n",
        "        tiled_up_circuits = tf.repeat(self.empty_circuit, repeats=batch_dim)\n",
        "        tiled_up_thetas = tf.tile(self.theta, multiples=[batch_dim, 1])\n",
        "        tiled_up_inputs = tf.tile(inputs[0], multiples=[1, self.n_layers])\n",
        "        scaled_inputs = tf.einsum(\"i,ji->ji\", self.lmbd, tiled_up_inputs)\n",
        "        squashed_inputs = tf.keras.layers.Activation(self.activation)(scaled_inputs)\n",
        "\n",
        "        joined_vars = tf.concat([tiled_up_thetas, squashed_inputs], axis=1)\n",
        "        joined_vars = tf.gather(joined_vars, self.indices, axis=1)\n",
        "        \n",
        "        return self.computation_layer([tiled_up_circuits, joined_vars])"
      ],
      "metadata": {
        "id": "Dr3jLEJGsIVY"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Alternating(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim):\n",
        "        super(Alternating, self).__init__()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=tf.constant([[(-1.)**i for i in range(output_dim)]]), dtype=\"float32\",\n",
        "            trainable=True, name=\"obs-weights\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w)"
      ],
      "metadata": {
        "id": "N3iO9UafJWoB"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 5 # Dimension of the state vectors in CartPole\n",
        "n_layers = 5 # Number of layers in the PQC\n",
        "n_actions = 2 # Number of actions in CartPole\n",
        "\n",
        "qubits = cirq.GridQubit.rect(1, n_qubits)"
      ],
      "metadata": {
        "id": "oZ58ren3JYR5"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ops = [cirq.Z(q) for q in qubits]\n",
        "observables = [reduce((lambda x, y: x * y), ops)] # Z_0*Z_1*Z_2*Z_3"
      ],
      "metadata": {
        "id": "VIWtQw9uJfiZ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model_policy(qubits, n_layers, n_actions, beta, observables):\n",
        "    \"\"\"Generates a Keras model for a data re-uploading PQC policy.\"\"\"\n",
        "\n",
        "    input_tensor = tf.keras.Input(shape=(len(qubits), ), dtype=tf.dtypes.float32, name='input')\n",
        "    re_uploading_pqc = ReUploadingPQC(qubits, n_layers, observables)([input_tensor])\n",
        "    process = tf.keras.Sequential([\n",
        "        Alternating(n_actions),\n",
        "        tf.keras.layers.Lambda(lambda x: x * beta),\n",
        "        tf.keras.layers.Softmax()\n",
        "    ], name=\"observables-policy\")\n",
        "    policy = process(re_uploading_pqc)\n",
        "    model = tf.keras.Model(inputs=[input_tensor], outputs=policy)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = generate_model_policy(qubits, n_layers, n_actions, 1.0, observables)"
      ],
      "metadata": {
        "id": "m51EcRH8JhIS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_returns(rewards_history, gamma):\n",
        "    \"\"\"Compute discounted returns with discount factor `gamma`.\"\"\"\n",
        "    returns = []\n",
        "    discounted_sum = 0\n",
        "    for r in rewards_history[::-1]:\n",
        "        discounted_sum = r + gamma * discounted_sum\n",
        "        returns.insert(0, discounted_sum)\n",
        "\n",
        "    # Normalize them for faster and more stable learning\n",
        "    returns = np.array(returns)\n",
        "    returns = (returns - np.mean(returns)) / (np.std(returns) + 1e-8)\n",
        "    returns = returns.tolist()\n",
        "    \n",
        "    return returns"
      ],
      "metadata": {
        "id": "vW727ueEJkGB"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_bounds = np.array([2.4, 2.5, 0.21, 2.5])\n",
        "gamma = 1\n",
        "batch_size = 10\n",
        "n_episodes = 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "_FlJ6xYNJltx",
        "outputId": "3fd5ca46-7217-4513-9572-93a6e2b8418b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-375edfbcf2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_in = tf.keras.optimizers.Adam(learning_rate=0.1, amsgrad=True)\n",
        "optimizer_var = tf.keras.optimizers.Adam(learning_rate=0.01, amsgrad=True)\n",
        "optimizer_out = tf.keras.optimizers.Adam(learning_rate=0.1, amsgrad=True)\n",
        "\n",
        "# Assign the model parameters to each optimizer\n",
        "w_in, w_var, w_out = 1, 0, 2"
      ],
      "metadata": {
        "id": "Iw6wyGqEJngh"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def reinforce_update(states, actions, returns, model):\n",
        "    states = tf.convert_to_tensor(states)\n",
        "    actions = tf.convert_to_tensor(actions)\n",
        "    returns = tf.convert_to_tensor(returns)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        logits = model(states)\n",
        "        p_actions = tf.gather_nd(logits, actions)\n",
        "        log_probs = tf.math.log(p_actions)\n",
        "        loss = tf.math.reduce_sum(-log_probs * returns) / batch_size\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    for optimizer, w in zip([optimizer_in, optimizer_var, optimizer_out], [w_in, w_var, w_out]):\n",
        "        optimizer.apply_gradients([(grads[w], model.trainable_variables[w])])"
      ],
      "metadata": {
        "id": "vPNmC7HRJq3h"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "def gather_episodes(state_bounds, n_actions, model, n_episodes, env_name):\n",
        "    \"\"\"Interact with environment in batched fashion.\"\"\"\n",
        "\n",
        "    trajectories = [defaultdict(list) for _ in range(n_episodes)]\n",
        "    envs = [gym.make(env_name) for _ in range(n_episodes)]\n",
        "\n",
        "    done = [False for _ in range(n_episodes)]\n",
        "    states = [e.reset() for e in envs]\n",
        "\n",
        "    while not all(done):\n",
        "        unfinished_ids = [i for i in range(n_episodes) if not done[i]]\n",
        "        normalized_states = [s/state_bounds for i, s in enumerate(states) if not done[i]]\n",
        "\n",
        "        for i, state in zip(unfinished_ids, normalized_states):\n",
        "            trajectories[i]['states'].append(state)\n",
        "            print(tf.convert_to_tensor(normalized_states))\n",
        "            print(state.shape)\n",
        "            \n",
        "\n",
        "        # Compute policy for all unfinished envs in parallel\n",
        "        states = tf.convert_to_tensor(normalized_states)\n",
        "        print(states)\n",
        "        time.sleep(5)\n",
        "        action_probs = model([states])\n",
        "        # Store action and transition all environments to the next state\n",
        "        states = [None for i in range(n_episodes)]\n",
        "        for i, policy in zip(unfinished_ids, action_probs.numpy()):\n",
        "            action = np.random.choice(n_actions, p=policy)\n",
        "            states[i], reward, done[i], _ = envs[i].step(action)\n",
        "            trajectories[i]['actions'].append(action)\n",
        "            trajectories[i]['rewards'].append(reward)\n",
        "\n",
        "    return trajectories"
      ],
      "metadata": {
        "id": "qkS0cmGjMPXe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "episode_reward_history = []\n",
        "for batch in range(n_episodes // batch_size):\n",
        "    # Gather episodes\n",
        "    episodes = gather_episodes(model, batch_size)\n",
        "\n",
        "    # Group states, actions and returns in numpy arrays\n",
        "    states = np.concatenate([ep['states'] for ep in episodes])\n",
        "    actions = np.concatenate([ep['actions'] for ep in episodes])\n",
        "    rewards = [ep['rewards'] for ep in episodes]\n",
        "    returns = np.concatenate([compute_returns(ep_rwds, gamma) for ep_rwds in rewards])\n",
        "    returns = np.array(returns, dtype=np.float32)\n",
        "\n",
        "    id_action_pairs = np.array([[i, a] for i, a in enumerate(actions)])\n",
        "\n",
        "    # Update model parameters.\n",
        "    reinforce_update(states, id_action_pairs, returns, model)\n",
        "\n",
        "    # Store collected rewards\n",
        "    for ep_rwds in rewards:\n",
        "        episode_reward_history.append(np.sum(ep_rwds))\n",
        "\n",
        "    avg_rewards = np.mean(episode_reward_history[-10:])\n",
        "\n",
        "    print('Finished episode', (batch + 1) * batch_size,\n",
        "          'Average rewards: ', avg_rewards)\n",
        "\n",
        "    if avg_rewards >= 500.0:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "RNtay_KMMTPN",
        "outputId": "a2316e4f-9c04-408f-c13e-618285bb4205"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-d0a4c2184c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Gather episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Group states, actions and returns in numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: gather_episodes() takes 2 positional arguments but 5 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training the agent\n",
        "episode_reward_history = []\n",
        "for batch in range(n_episodes // batch_size):\n",
        "    # Gather episodes\n",
        "    episodes = gather_episodes(batch_size, model)\n",
        "\n",
        "    # Group states, actions and returns in numpy arrays\n",
        "    states = np.concatenate([ep['states'] for ep in episodes])\n",
        "    actions = np.concatenate([ep['actions'] for ep in episodes])\n",
        "    rewards = [ep['rewards'] for ep in episodes]\n",
        "    returns = np.concatenate([compute_returns(ep_rwds, gamma) for ep_rwds in rewards])\n",
        "    returns = np.array(returns, dtype=np.float32)\n",
        "\n",
        "    id_action_pairs = np.array([[i, a] for i, a in enumerate(actions)])\n",
        "\n",
        "    # Update model parameters.\n",
        "    reinforce_update(states, id_action_pairs, returns, model)\n",
        "\n",
        "    # Store collected rewards\n",
        "    for ep_rwds in rewards:\n",
        "        episode_reward_history.append(np.sum(ep_rwds))\n",
        "\n",
        "    avg_rewards = np.mean(episode_reward_history[-10:])\n",
        "\n",
        "    print('Finished episode', (batch + 1) * batch_size,\n",
        "          'Average rewards: ', avg_rewards)\n",
        "\n",
        "    # if avg_rewards >= 500.0:\n",
        "    #     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zQ58_P3CUnaM",
        "outputId": "46a1a9fc-8216-427d-d49c-c74b7dbb356e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 30.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 10 Average rewards:  -594.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 20 Average rewards:  -23.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 30 Average rewards:  -894.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 40 Average rewards:  -42.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 35.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 50 Average rewards:  283.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 51.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 60 Average rewards:  427.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 70 Average rewards:  210.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 80 Average rewards:  -756.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 90 Average rewards:  -509.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 100 Average rewards:  -1068.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 110 Average rewards:  168.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 120 Average rewards:  -222.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 130 Average rewards:  -109.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 140 Average rewards:  -228.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 150 Average rewards:  -216.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 160 Average rewards:  -30.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 170 Average rewards:  198.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 180 Average rewards:  -83.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 190 Average rewards:  53.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 28.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 200 Average rewards:  -210.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 210 Average rewards:  -1206.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 51.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 220 Average rewards:  233.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 230 Average rewards:  -714.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 240 Average rewards:  -324.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 250 Average rewards:  -60.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 52.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 260 Average rewards:  -144.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 31.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 270 Average rewards:  0.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 52.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 280 Average rewards:  -180.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 290 Average rewards:  -414.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 300 Average rewards:  54.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 31.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 310 Average rewards:  -930.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 320 Average rewards:  -427.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 51.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 330 Average rewards:  -468.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 30.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 340 Average rewards:  995.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 350 Average rewards:  145.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 50.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 360 Average rewards:  -233.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 48.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 370 Average rewards:  -732.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 40.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 380 Average rewards:  317.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 35.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 390 Average rewards:  -461.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 400 Average rewards:  13.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 410 Average rewards:  -16.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 420 Average rewards:  -907.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 430 Average rewards:  -882.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 440 Average rewards:  -126.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 450 Average rewards:  486.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 37.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 460 Average rewards:  362.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 470 Average rewards:  286.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 480 Average rewards:  -232.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 490 Average rewards:  126.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 35.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 500 Average rewards:  101.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 510 Average rewards:  -108.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 520 Average rewards:  174.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 530 Average rewards:  558.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 540 Average rewards:  -276.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 550 Average rewards:  36.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 560 Average rewards:  -557.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 50.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 570 Average rewards:  -186.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 580 Average rewards:  360.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 590 Average rewards:  -30.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 600 Average rewards:  377.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 610 Average rewards:  618.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 620 Average rewards:  -540.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 630 Average rewards:  108.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 640 Average rewards:  179.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 650 Average rewards:  781.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 660 Average rewards:  6.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 670 Average rewards:  204.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 680 Average rewards:  222.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 48.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 690 Average rewards:  19.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 700 Average rewards:  89.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 710 Average rewards:  342.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 720 Average rewards:  1296.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 35.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 730 Average rewards:  -695.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 35.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 740 Average rewards:  0.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 51.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 750 Average rewards:  -426.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 760 Average rewards:  443.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 770 Average rewards:  474.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 780 Average rewards:  571.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 52.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 790 Average rewards:  336.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 800 Average rewards:  -282.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 810 Average rewards:  303.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 37.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 820 Average rewards:  360.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 830 Average rewards:  425.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 54.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 840 Average rewards:  -300.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 850 Average rewards:  -72.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 860 Average rewards:  456.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 870 Average rewards:  -245.6\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 880 Average rewards:  84.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 890 Average rewards:  -150.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 51.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 900 Average rewards:  -18.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 910 Average rewards:  73.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 59.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 920 Average rewards:  365.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 930 Average rewards:  894.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 940 Average rewards:  88.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 52.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 950 Average rewards:  -1062.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 960 Average rewards:  438.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 970 Average rewards:  648.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 980 Average rewards:  -246.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 990 Average rewards:  6.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1000 Average rewards:  -438.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1010 Average rewards:  156.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 55.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1020 Average rewards:  -265.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 46.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1030 Average rewards:  732.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1040 Average rewards:  511.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1050 Average rewards:  175.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 50.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1060 Average rewards:  503.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 37.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1070 Average rewards:  -396.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 31.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1080 Average rewards:  1062.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1090 Average rewards:  211.2\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 53.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1100 Average rewards:  -112.8\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1110 Average rewards:  -660.4\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished episode 1120 Average rewards:  714.0\n",
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 57.10it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-3f6cf9128b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Update model parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mreinforce_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_action_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Store collected rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "# from Environment import Actor\n",
        "from Rudder import LessonBuffer\n",
        "from Environment import Environment\n",
        "from Rudder import RRLSTM as LSTM\n",
        "import torch\n",
        "import time as Time\n",
        "import random\n",
        "from PolicyUpdater import PolicyUpdater\n",
        "from tqdm import tqdm\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "\n",
        "\n",
        "environment = Environment(1000,100)\n",
        "environment.CreateStates()\n",
        "episode = 0\n",
        "for i in (range(10)):\n",
        "    episode += 1\n",
        "    environment.reset_paramter()\n",
        "    state, _ = environment.reset_state()\n",
        "    if state[1] == \"Ch1\":\n",
        "        state[1] = 1\n",
        "    else:\n",
        "        state[1] = 0\n",
        "    environment.generate_channel_state_list_for_whole_sequence(state[1])\n",
        "    rewards = []\n",
        "    states = [state]\n",
        "    actions = []\n",
        "    done = False\n",
        "    name = f'({state[0]}, {state[1]}, {state[2]}, {state[3]}, {state[4]})'\n",
        "    print(state)\n",
        "    policy = (model([tf.convert_to_tensor([state.astype(float)])])).numpy()\n",
        "    print(policy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pef0M_ZVzju",
        "outputId": "89d8f722-b1e3-43f7-bf4c-d78cb6ffe64c"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2, 0.8], [0.30000000000000004, 0.7]]\n",
            "433992\n",
            "['254' '1' '500' '1' '0']\n",
            "[[0.42634773 0.57365227]]\n",
            "['190' '0' '500' '1' '0']\n",
            "[[0.6719596  0.32804036]]\n",
            "['314' '1' '500' '1' '0']\n",
            "[[0.5415739  0.45842615]]\n",
            "['206' '0' '500' '1' '0']\n",
            "[[0.39830992 0.6016901 ]]\n",
            "['186' '0' '500' '1' '0']\n",
            "[[0.5218888 0.4781112]]\n",
            "['26' '1' '500' '1' '0']\n",
            "[[0.5833635  0.41663653]]\n",
            "['26' '0' '500' '1' '0']\n",
            "[[0.3310493  0.66895074]]\n",
            "['330' '1' '500' '1' '0']\n",
            "[[0.80166745 0.19833252]]\n",
            "['310' '1' '500' '1' '0']\n",
            "[[0.4538349 0.5461651]]\n",
            "['142' '0' '500' '1' '0']\n",
            "[[0.6720333 0.3279667]]\n"
          ]
        }
      ]
    }
  ]
}