{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9pbmdfCdOgJJhX+iDcDxM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirhoseinaghaei/Research_Simulation/blob/main/Untitled34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WheK6dLV4PQw",
        "outputId": "f8d883ab-f776-4d1e-fa6d-1a9eef96a5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/nn.py:741: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  for k, v in self.lstm_inlets_activations.items() if v[0] is not 1])\n",
            "/content/nn.py:747: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  for k, v in self.lstm_inlets_activations.items() if v[0] is not 1])\n",
            "/content/nn.py:753: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  for k, v in self.lstm_inlets_activations.items() if v[0] is not 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5, 0.5], [1.0, 0.0]]\n",
            "[[0.5, 0.5], [1.0, 0.0]]\n",
            "275\n",
            "HI\n",
            "BYE\n",
            "300\n",
            "HI\n",
            "BYE\n",
            "325\n",
            "HI\n",
            "BYE\n",
            "350\n",
            "HI\n",
            "BYE\n",
            "375\n",
            "HI\n",
            "BYE\n",
            "400\n",
            "HI\n",
            "BYE\n",
            "425\n",
            "HI\n",
            "BYE\n",
            "450\n",
            "HI\n",
            "BYE\n",
            "475\n",
            "HI\n",
            "BYE\n",
            "500\n",
            "HI\n",
            "BYE\n",
            "525\n",
            "HI\n",
            "BYE\n",
            "550\n",
            "HI\n",
            "BYE\n",
            "575\n",
            "HI\n",
            "BYE\n",
            "600\n",
            "HI\n",
            "BYE\n",
            "625\n",
            "HI\n",
            "BYE\n",
            "650\n",
            "HI\n",
            "BYE\n",
            "675\n",
            "HI\n",
            "BYE\n",
            "700\n",
            "HI\n",
            "BYE\n",
            "725\n",
            "HI\n",
            "BYE\n",
            "750\n",
            "HI\n",
            "BYE\n",
            "775\n",
            "HI\n",
            "BYE\n",
            "800\n",
            "HI\n",
            "BYE\n",
            "825\n",
            "HI\n",
            "BYE\n",
            "850\n",
            "HI\n",
            "BYE\n",
            "875\n",
            "HI\n",
            "BYE\n",
            "900\n",
            "HI\n",
            "BYE\n",
            "925\n",
            "HI\n",
            "BYE\n",
            "950\n",
            "HI\n",
            "BYE\n",
            "975\n",
            "HI\n",
            "BYE\n",
            "1000\n",
            "HI\n",
            "BYE\n",
            "1025\n",
            "HI\n",
            "BYE\n",
            "1050\n",
            "HI\n",
            "BYE\n",
            "1075\n",
            "HI\n",
            "BYE\n",
            "1100\n",
            "HI\n",
            "BYE\n",
            "1125\n",
            "HI\n",
            "BYE\n",
            "1150\n",
            "HI\n",
            "BYE\n",
            "1175\n",
            "HI\n",
            "BYE\n",
            "1200\n",
            "HI\n",
            "BYE\n",
            "1225\n",
            "HI\n",
            "BYE\n",
            "1250\n",
            "HI\n",
            "BYE\n",
            "1275\n",
            "HI\n",
            "BYE\n",
            "1300\n",
            "HI\n",
            "BYE\n",
            "1325\n",
            "HI\n",
            "BYE\n",
            "1350\n",
            "HI\n",
            "BYE\n",
            "1375\n",
            "HI\n",
            "BYE\n",
            "1400\n",
            "HI\n",
            "BYE\n",
            "1425\n",
            "HI\n",
            "BYE\n",
            "1450\n",
            "HI\n",
            "BYE\n",
            "1475\n",
            "HI\n",
            "BYE\n",
            "1500\n",
            "HI\n",
            "BYE\n",
            "1525\n",
            "HI\n",
            "BYE\n",
            "1550\n",
            "HI\n",
            "BYE\n",
            "1575\n",
            "HI\n",
            "BYE\n",
            "1600\n",
            "HI\n",
            "BYE\n",
            "1625\n",
            "HI\n",
            "BYE\n",
            "1650\n",
            "HI\n",
            "BYE\n",
            "1675\n",
            "HI\n",
            "BYE\n",
            "1700\n",
            "HI\n",
            "BYE\n",
            "1725\n",
            "HI\n",
            "BYE\n",
            "1750\n",
            "HI\n",
            "BYE\n",
            "1775\n",
            "HI\n",
            "BYE\n",
            "1800\n",
            "HI\n",
            "BYE\n",
            "1825\n",
            "HI\n",
            "BYE\n",
            "1850\n",
            "HI\n",
            "BYE\n",
            "1875\n",
            "HI\n",
            "BYE\n",
            "1900\n",
            "HI\n",
            "BYE\n",
            "1925\n",
            "HI\n",
            "BYE\n",
            "1950\n",
            "HI\n",
            "BYE\n",
            "1975\n",
            "HI\n",
            "BYE\n",
            "2000\n",
            "HI\n",
            "BYE\n",
            "(32, Ch1, 100, 1, 0)               0 8.360027313232422\n",
            "(32, Ch2, 100, 1, 0)               0 8.06385326385498\n",
            "(35, Ch1, 100, 1, 0)               0 7.692844867706299\n",
            "(35, Ch2, 100, 1, 0)               0 8.00780200958252\n",
            "(62, Ch1, 100, 1, 0)               0 0.5346525311470032\n",
            "(62, Ch2, 100, 1, 0)               0 7.947994709014893\n",
            "(65, Ch1, 100, 1, 0)               0 7.69276237487793\n",
            "(65, Ch2, 100, 1, 0)               0 7.73726749420166\n",
            "(92, Ch1, 100, 1, 0)               0 1.2198607921600342\n",
            "(92, Ch2, 100, 1, 0)               0 7.39575719833374\n",
            "(95, Ch1, 100, 1, 0)               0 7.93791389465332\n",
            "(95, Ch2, 100, 1, 0)               0 7.822963714599609\n",
            "(122, Ch1, 100, 1, 0)               0 7.699808120727539\n",
            "(122, Ch2, 100, 1, 0)               0 8.046719551086426\n",
            "(125, Ch1, 100, 1, 0)               0 0.8028619289398193\n",
            "(125, Ch2, 100, 1, 0)               0 8.016260147094727\n",
            "(35, Ch1, 100, 1, 0)              51\n",
            "(35, Ch2, 100, 1, 0)              96\n",
            "(62, Ch1, 100, 1, 0)              11\n",
            "(32, Ch2, 100, 1, 0)              85\n",
            "(32, Ch1, 100, 1, 0)             116\n",
            "(95, Ch1, 100, 1, 0)              40\n",
            "(62, Ch2, 100, 1, 0)             114\n",
            "(92, Ch2, 100, 1, 0)             118\n",
            "(125, Ch1, 100, 1, 0)               9\n",
            "(65, Ch1, 100, 1, 0)              79\n",
            "(122, Ch2, 100, 1, 0)             102\n",
            "(122, Ch1, 100, 1, 0)             119\n",
            "(125, Ch2, 100, 1, 0)             112\n",
            "(95, Ch2, 100, 1, 0)             113\n",
            "(92, Ch1, 100, 1, 0)               8\n",
            "(65, Ch2, 100, 1, 0)             108\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# from Environment import Actor\n",
        "from Rudder import LessonBuffer\n",
        "from Environment import Environment\n",
        "from Rudder import RRLSTM as LSTM\n",
        "import torch\n",
        "import time as Time\n",
        "import random\n",
        "from PolicyUpdater import PolicyUpdater\n",
        "\n",
        "lb_size = 2048\n",
        "n_lstm = 16\n",
        "max_time = 50\n",
        "policy_lr = 0.1\n",
        "lstm_lr = 1e-2\n",
        "l2_regularization = 1e-6\n",
        "avg_window = 750\n",
        "\n",
        "Lesson_buffer = LessonBuffer(1000, 25, 5)\n",
        "episode = 0\n",
        "rudder_lstm = LSTM(state_input_size=5, n_actions= 2, buffer=Lesson_buffer, n_units=n_lstm,\n",
        "                        lstm_lr=lstm_lr, l2_regularization=l2_regularization, return_scaling=10,\n",
        "                        lstm_batch_size=8, continuous_pred_factor=0.5)\n",
        "\n",
        "# rudder_lstm.load_state_dict(torch.load('rudder_lstm.pt'))\n",
        "environment = Environment(100,25)\n",
        "environment.CreateStates()\n",
        "# print(type(environment.StateList[0].Name))\n",
        "policy_updator  = PolicyUpdater(environment= environment, lr = policy_lr)\n",
        "episode = 0\n",
        "visited_dict = {}\n",
        "for i in range(2000):\n",
        "    episode += 1\n",
        "    environment.reset_paramter()\n",
        "    state = environment.reset_state()\n",
        "    rewards = []\n",
        "    states = [state]\n",
        "    actions = []\n",
        "    done = False\n",
        "    name = f'({state[0]}, {state[1]}, {state[2]}, {state[3]}, {state[4]})'\n",
        "\n",
        "    while not done:\n",
        "        if np.random.random() < 0.05:\n",
        "            action = np.random.choice(2)\n",
        "            if len(states) == 1 and action == 0:\n",
        "              if name not in visited_dict.keys(): \n",
        "                  visited_dict[name] = 1\n",
        "              else:\n",
        "                  visited_dict[name] += 1\n",
        "    \n",
        "        else:\n",
        "            action = 0 if policy_updator.Quality[name,0] > policy_updator.Quality[name,1] else 1          \n",
        "            if len(states) == 1 and action == 0:\n",
        "              if name not in visited_dict.keys(): \n",
        "                  visited_dict[name] = 1\n",
        "              else:\n",
        "                  visited_dict[name] += 1\n",
        "        if environment.state.Ra == 0 and environment.state.U == 0:\n",
        "            action = 0\n",
        "        if environment.state.Ra == 0 and environment.state.U == 24:\n",
        "            action = 1\n",
        "        if environment.state.U > 0:\n",
        "            action = 0\n",
        "        state, reward, done = environment.step(action)\n",
        "    \n",
        "        actions.append(action)\n",
        "        states.append(state)\n",
        "        rewards.append(reward) \n",
        "        if done: \n",
        "\n",
        "            res = np.nonzero(rewards)[0]\n",
        "            if len(res) > 0 :\n",
        "              # print(res)\n",
        "              rewards[-1] = rewards[res[0]]\n",
        "              rewards[res[0]] = 0   \n",
        "            for i in states: \n",
        "                if i[1] == \"Ch1\":\n",
        "                    i[1] = 1\n",
        "                else:\n",
        "                    i[1] = 0\n",
        "            states = np.stack(states)\n",
        "            states = states.astype(int)\n",
        "            rewards = np.array(rewards, dtype = np.float32)\n",
        "            actions = np.array(actions)\n",
        "            Lesson_buffer.add(states = states, actions = actions, rewards = rewards)\n",
        "            if  Lesson_buffer.full_enough() and Lesson_buffer.different_returns_encountered()  :\n",
        "                    # print(\"different_returns_encountered\")        \n",
        "                    # If RUDDER is run, the LSTM is trained after each episode until its loss is below a threshold.\n",
        "                    # Samples will be drawn from the lessons buffer.\n",
        "                    if episode % 25 == 0:\n",
        "\n",
        "                        # print(\"True\")\n",
        "                        print(episode)\n",
        "                        rudder_lstm.train(episode=episode)\n",
        "                    if episode >= 1600: \n",
        "                        torch.save(rudder_lstm.state_dict(), 'rudder_lstm.pt')\n",
        "                    # Then the LSTM is used to redistribute the reward.\n",
        "            # print(rewards)\n",
        "            # print(states)\n",
        "            # print(actions)\n",
        "            rewards = rudder_lstm.redistribute_reward(states=np.expand_dims(states, 0),actions=np.expand_dims(actions, 0))[0, :]\n",
        "            policy_updator.Q_estimation(actions= actions , states = states, rewards= rewards)\n",
        "            # print(rewards)\n",
        "\n",
        "for keys, value in policy_updator.Quality.items():\n",
        "         initial_StateName = []\n",
        "         for i in environment.initial_State:\n",
        "            initial_StateName.append(i.Name) \n",
        "         if keys[0] in initial_StateName and keys[1] == 0: \n",
        "            print('{:15} {:15} {:15}'.format( keys[0] ,  keys[1], value))\n",
        "for value in visited_dict:\n",
        "        print('{:15} {:15}'.format( value, visited_dict[value]))\n",
        "  "
      ]
    }
  ]
}